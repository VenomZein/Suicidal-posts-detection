{
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Full preprocessing | Tuned CNN, GRU, LSTM 93%Acc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2250642,
          "sourceType": "datasetVersion",
          "datasetId": 1075326
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'suicide-watch:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1075326%2F2250642%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240314%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240314T061152Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dabc9d404ebf1fbf06174f6029cd1b4a199ae0dacfad7a67434a65eaa1af2be101db892531ebbfaab3ddb758993feb15df4c5fcca4c5ce56608fe34a1df9e32c39b596a9af1682e3a792bc3309c66236bfad6f822f25a58220e6e04341792bc1f09df1b7ae4786a0e60c6b8c7ba4688be6ff5293dafe8ce2213e516a0f14639e57bbd2a02f8a05f9791df1f197903bf8e62b7d301ac98b0b970b24a53aeb8628f8ac2ca3c97e171bdaf06efb76be07b57ee0ee0cd4b87b5e7a30703afdcee3693505186275dc52506496ab240834f5c0c83ee0082478c8dc01f7fa3807f89dc6dab6e3fb3a4b863060c420a9ca3076c9b6d7e7787a1114e516051be0d1de78e96'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WS5w6OE0lrOs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "VBDQZLYPidFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "import wordcloud\n",
        "from langdetect import detect\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.corpus import words"
      ],
      "metadata": {
        "id": "phIJDG8Iiekl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load & Read Dataset"
      ],
      "metadata": {
        "id": "fybtXQj8imTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V1vxXFo6im_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Suicide_Detection.csv')"
      ],
      "metadata": {
        "id": "gHe4UwYrivNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "nfKwKkvFiy7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check top observations"
      ],
      "metadata": {
        "id": "-_ZSJMili6YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "I3C-RvA4izpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Dimension, No.of Row & Column"
      ],
      "metadata": {
        "id": "spEuZMmri7MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dimensions of the data\n",
        "print(\"Dimension: \",df.shape)\n",
        "\n",
        "# Number of rows and columns\n",
        "print(\"Number of rows in data =\",df.shape[0])\n",
        "print(\"Number of columns in data =\",df.shape[1])\n",
        "\n",
        "# Print the column names\n",
        "column_names = df.columns\n",
        "print(column_names)"
      ],
      "metadata": {
        "id": "ZvNZPHyZi8-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Summary"
      ],
      "metadata": {
        "id": "VPztmvQsi__3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Unnamed: 0'].is_unique"
      ],
      "metadata": {
        "id": "raHCKe3F7fnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "SGOuehZyjBsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Missing Value"
      ],
      "metadata": {
        "id": "HFEuXRHmjEXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Check for missing values in the dataset\")\n",
        "null_check=df.isnull().sum()\n",
        "print(null_check)"
      ],
      "metadata": {
        "id": "Q49Aql0mjFHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Duplicates"
      ],
      "metadata": {
        "id": "jszbQn1ejHRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate rows in the entire DataFrame\n",
        "duplicate_rows = df.duplicated()\n",
        "\n",
        "# Count the number of duplicate rows\n",
        "num_duplicates = duplicate_rows.sum()\n",
        "\n",
        "# Display the duplicate rows\n",
        "duplicate_data = df[duplicate_rows]\n",
        "\n",
        "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
        "print(\"Duplicate rows:\")\n",
        "print(duplicate_data)"
      ],
      "metadata": {
        "id": "PyUqfklFjIze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution of Class"
      ],
      "metadata": {
        "id": "31T-R1esjLX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()"
      ],
      "metadata": {
        "id": "70WQrE7gjM33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df['class'],binwidth=0.5)"
      ],
      "metadata": {
        "id": "DbJexdjgjPkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Cloud"
      ],
      "metadata": {
        "id": "mfSea2h_jTnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suicide=df[df['class']=='suicide']['text']\n",
        "xsuicide=df[df['class']=='non-suicide']['text']\n",
        "\n",
        "def display_cloud(data):\n",
        "    plt.subplots(figsize=(10,10))\n",
        "    wc = wordcloud.WordCloud(\n",
        "                   background_color=\"black\",\n",
        "                   colormap='viridis',\n",
        "                   max_words=1000,\n",
        "                   random_state=24)\n",
        "    plt.imshow(wc.generate(' '.join(data)))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_cloud(suicide)"
      ],
      "metadata": {
        "id": "yO1GQ93rjUe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_cloud1(data):\n",
        "    plt.subplots(figsize=(10,10))\n",
        "    wc = wordcloud.WordCloud(\n",
        "                   background_color=\"white\",\n",
        "                   max_words=1000,\n",
        "                   random_state=24)\n",
        "    plt.imshow(wc.generate(' '.join(data)))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_cloud1(xsuicide)"
      ],
      "metadata": {
        "id": "xdqWcKa8B2hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Length of Text"
      ],
      "metadata": {
        "id": "N83pDquxjZKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyse the count of words in each segment- both positive and negative reviews\n",
        "# Function for checking word length\n",
        "def cal_len(data):\n",
        "    return len(data)\n",
        "\n",
        "# Create generic plotter with Seaborn\n",
        "def plot_count(count_suicide, count_xsuicide, xlim_range=None):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    sns.distplot(count_suicide, ax=ax1, color='Orange')\n",
        "    ax1.set_title(\"Suicide Text Length\")\n",
        "\n",
        "    sns.distplot(count_xsuicide, ax=ax2, color='Green')\n",
        "    ax2.set_title(\"Non-suicide Text Length\")\n",
        "\n",
        "    # Set x-axis range if specified\n",
        "    if xlim_range:\n",
        "        ax1.set_xlim(xlim_range)\n",
        "        ax2.set_xlim(xlim_range)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you want to set the x-axis range from 0 to 1000\n",
        "xlim_range = (0, 1000)\n",
        "\n",
        "count_suicide_words = suicide.str.split().apply(lambda z: cal_len(z))\n",
        "count_xsuicide_words = xsuicide.str.split().apply(lambda z: cal_len(z))\n",
        "\n",
        "plot_count(count_suicide_words, count_xsuicide_words, xlim_range)"
      ],
      "metadata": {
        "id": "ikHkbHgNjZ60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "XoA3vb0nk_fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lowercasing"
      ],
      "metadata": {
        "id": "946VtmtglAKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercasing\n",
        "df['text'] = df['text'].str.lower()"
      ],
      "metadata": {
        "id": "Xa9s3roelCPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "nBAQ22ullFHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing '"
      ],
      "metadata": {
        "id": "tn1wwZoZlHPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].str.replace(\"â€™\", \"'\")"
      ],
      "metadata": {
        "id": "WIMp6548lWzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "B9d4A0zmlZBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replace Abbreviations"
      ],
      "metadata": {
        "id": "f7EuM2P_lYey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abb = {\n",
        "  \"ain't\": \"am not\",\n",
        "  \"aren't\": \"are not\",\n",
        "  \"can't\": \"cannot\",\n",
        "  \"can't've\": \"cannot have\",\n",
        "  \"'cause\": \"because\",\n",
        "  \"could've\": \"could have\",\n",
        "  \"couldn't\": \"could not\",\n",
        "  \"couldn't've\": \"could not have\",\n",
        "  \"didn't\": \"did not\",\n",
        "  \"doesn't\": \"does not\",\n",
        "  \"don't\": \"do not\",\n",
        "  \"dont\": \"do not\",\n",
        "  \"hadn't\": \"had not\",\n",
        "  \"hadn't've\": \"had not have\",\n",
        "  \"hasn't\": \"has not\",\n",
        "  \"haven't\": \"have not\",\n",
        "  \"he'd\": \"he would\",\n",
        "  \"idk\": \"i do not know\",\n",
        "  \"he'd've\": \"he would have\",\n",
        "  \"he'll\": \"he will\",  \"he'll've\": \"he will have\",\n",
        "  \"he's\": \"he is\",\n",
        "  \"how'd\": \"how did\",\n",
        "  \"how'd'y\": \"how do you\",\n",
        "  \"how'll\": \"how will\",\n",
        "  \"how's\": \"how is\",\n",
        "  \"i'd\": \"i would\",\n",
        "  \"i'd've\": \"i would have\",\n",
        "  \"i'll\": \"i will\",\n",
        "  \"i'll've\": \"i will have\",\n",
        "  \"i'm\": \"i am\",\n",
        "  \"im\": \"i am\",\n",
        "  \"i've\": \"i have\",\n",
        "  \"isn't\": \"is not\",\n",
        "  \"it'd\": \"it had\",\n",
        "  \"it'd've\": \"it would have\",\n",
        "  \"it'll\": \"it will\",\n",
        "  \"it'll've\": \"it will have\",\n",
        "  \"it's\": \"it is\", \"let's\": \"let us\",\n",
        "  \"ma'am\": \"madam\",\n",
        "  \"mayn't\": \"may not\",\n",
        "  \"might've\": \"might have\",\n",
        "  \"mightn't\": \"might not\",\n",
        "  \"mightn't've\": \"might not have\",\n",
        "  \"must've\": \"must have\",\n",
        "  \"mustn't\": \"must not\",\n",
        "  \"mustn't've\": \"must not have\",\n",
        "  \"needn't\": \"need not\",\n",
        "  \"needn't've\": \"need not have\",\n",
        "  \"o'clock\": \"of the clock\",\n",
        "  \"oughtn't\": \"ought not\",\n",
        "  \"oughtn't've\": \"ought not have\",\n",
        "  \"shan't\": \"shall not\",\n",
        "  \"sha'n't\": \"shall not\",\n",
        "  \"shan't've\": \"shall not have\",\n",
        "  \"she'd\": \"she would\",\n",
        "  \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n",
        "  \"she'll've\": \"she will have\",\n",
        "  \"she's\": \"she is\",\n",
        "  \"should've\": \"should have\",\n",
        "  \"shouldn't\": \"should not\",\n",
        "  \"shouldn't've\": \"should not have\",\n",
        "  \"so've\": \"so have\",\n",
        "  \"so's\": \"so is\",\n",
        "  \"that'd\": \"that would\",\n",
        "  \"that'd've\": \"that would have\",\n",
        "  \"that's\": \"that is\",\n",
        "  \"there'd\": \"there had\",\n",
        "  \"there'd've\": \"there would have\",\n",
        "  \"there's\": \"there is\",\n",
        "  \"they'd\": \"they would\",\n",
        "  \"they'd've\": \"they would have\",\n",
        "  \"they'll\": \"they will\",\n",
        "  \"they'll've\": \"they will have\",\n",
        "  \"they're\": \"they are\",\n",
        "  \"they've\": \"they have\",      \"to've\": \"to have\",\n",
        "  \"wasn't\": \"was not\",\n",
        "  \"we'd\": \"we had\",\n",
        "  \"we'd've\": \"we would have\",\n",
        "  \"we'll\": \"we will\",\n",
        "  \"we'll've\": \"we will have\",\n",
        "  \"we're\": \"we are\",\n",
        "  \"we've\": \"we have\",\n",
        "  \"weren't\": \"were not\",\n",
        "  \"what'll\": \"what will\",\n",
        "  \"what'll've\": \"what will have\",\n",
        "  \"what're\": \"what are\",\n",
        "  \"what's\": \"what is\",\n",
        "  \"what've\": \"what have\",\n",
        "  \"when's\": \"when is\",\n",
        "  \"when've\": \"when have\",\n",
        "  \"where'd\": \"where did\",\n",
        "  \"where's\": \"where is\",\n",
        "  \"where've\": \"where have\", \"who'll\": \"who will\",\n",
        "  \"who'll've\": \"who will have\",\n",
        "  \"who's\": \"who is\",\n",
        "  \"who've\": \"who have\",\n",
        "  \"why's\": \"why is\",\n",
        "  \"why've\": \"why have\",\n",
        "  \"will've\": \"will have\",\n",
        "  \"won't\": \"will not\",\n",
        "  \"won't've\": \"will not have\",\n",
        "  \"would've\": \"would have\",\n",
        "  \"wouldn't\": \"would not\",\n",
        "  \"wouldn't've\": \"would not have\",\n",
        "  \"y'all\": \"you all\",\n",
        "  \"y'alls\": \"you alls\",\n",
        "  \"y'all'd\": \"you all would\",\n",
        "  \"y'all'd've\": \"you all would have\",\n",
        "  \"y'all're\": \"you all are\",\n",
        "  \"y'all've\": \"you all have\",\n",
        "  \"you'd\": \"you had\",\n",
        "  \"you'd've\": \"you would have\", \"you'll\": \"you you will\",\n",
        "  \"you'll've\": \"you you will have\",\n",
        "  \"you're\": \"you are\",\n",
        "  \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "abb_re = re.compile('(%s)' % '|'.join(abb.keys()))\n",
        "\n",
        "def expandContractions(text, abb_re=abb_re):\n",
        "    def replace(match):\n",
        "        return abb[match.group(0)]\n",
        "    return abb_re.sub(replace, text)\n",
        "\n",
        "df['text'] = df['text'].apply(expandContractions)"
      ],
      "metadata": {
        "id": "626uTNmLldYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "hOnqfEV7ljBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization *3mins"
      ],
      "metadata": {
        "id": "V1swaOsYlgxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Apply tokenization to the text column in the DataFrame\n",
        "df['text'] = df['text'].apply(tokenize_text)"
      ],
      "metadata": {
        "id": "Y_x1fA_Glm2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "k4vBojI5wSBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Segmentation *7mins"
      ],
      "metadata": {
        "id": "11EPYLP6gIeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wordninja"
      ],
      "metadata": {
        "id": "NQ2L9K1ceRIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import wordninja\n",
        "import re\n",
        "\n",
        "# Apply word segmentation tot he 'text' column in the DataFrame\n",
        "df['text'] = df['text'].apply(lambda tokens: wordninja.split(\" \".join(tokens)))"
      ],
      "metadata": {
        "id": "WytAXqJGo6Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "pz3lVrn0es0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Stop Words, Punctuations & Numbers"
      ],
      "metadata": {
        "id": "pLR2fdkXlrE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to remove stopwords from a list of tokens\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens_without_stopwords = [\n",
        "        token for token in tokens if token.lower() not in stop_words]\n",
        "    return tokens_without_stopwords\n",
        "\n",
        "# Function to remove punctuation from a list of tokens\n",
        "def remove_punctuation(tokens):\n",
        "    tokens_without_punctuation = [token for token in tokens if token.isalnum()]\n",
        "    return tokens_without_punctuation\n",
        "\n",
        "# Function to remove numbers from a list of tokens\n",
        "def remove_numbers(tokens):\n",
        "    tokens_without_numbers = [token for token in tokens if not token.isdigit()]\n",
        "    return tokens_without_numbers\n",
        "\n",
        "# Apply the functions to the text column in the DataFrame\n",
        "df['text'] = df['text'].apply(remove_stopwords)\n",
        "df['text'] = df['text'].apply(remove_punctuation)\n",
        "df['text'] = df['text'].apply(remove_numbers)"
      ],
      "metadata": {
        "id": "to6YfoNilwvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "0dWfmZ_xlyn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove White Spaces, Symbols, Digits & Special Characters"
      ],
      "metadata": {
        "id": "hvVT-5Bxl0Fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove extra whitespaces from each word in a list\n",
        "def remove_whitespace(tokens):\n",
        "    cleaned_tokens = [token.strip() for token in tokens]\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Function to remove symbols and digits from each word in a list\n",
        "def remove_symbols_digits(tokens):\n",
        "    cleaned_tokens = [re.sub('[^a-zA-Z\\s]', ' ', token) for token in tokens]\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Function to remove special characters from each word in a list\n",
        "def remove_special(tokens):\n",
        "    cleaned_tokens = [token.replace(\"\\r\", \" \").replace(\"\\n\", \" \") for token in tokens]\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Apply other preprocessing functions\n",
        "df['text'] = df['text'].apply(remove_whitespace)\n",
        "df['text'] = df['text'].apply(remove_symbols_digits)\n",
        "df['text'] = df['text'].apply(remove_special)"
      ],
      "metadata": {
        "id": "cQnrt1ell6zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "l2OX3CW7l8-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove URLs, Email & Emoji"
      ],
      "metadata": {
        "id": "YG91sAxHl-ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to remove URLs from a list of strings\n",
        "def remove_url(tokens):\n",
        "    cleaned_tokens = [re.sub(r'http\\S+', '', token) for token in tokens]\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Function to remove email addresses from a list of strings\n",
        "def remove_mail(tokens):\n",
        "    cleaned_tokens = [re.sub(r'\\S+@\\S+', '', token) for token in tokens]\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Function to remove emojis from a list of strings\n",
        "def remove_emoji(tokens):\n",
        "    cleaned_tokens = [re.sub(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FB00-\\U0001FBFF\\U0001FE00-\\U0001FE0F\\U0001F004]+', '', token) for token in tokens]\n",
        "    return cleaned_tokens\n",
        "\n",
        "# Apply the functions to the 'text' column\n",
        "df['text'] = df['text'].apply(remove_url)\n",
        "df['text'] = df['text'].apply(remove_mail)\n",
        "df['text'] = df['text'].apply(remove_emoji)"
      ],
      "metadata": {
        "id": "fUHXAkn-mJOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "7XmzR8fRoLfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove words with only 2 characters"
      ],
      "metadata": {
        "id": "P2uCldElocAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(lambda x: [word for word in x if len(word) > 2])"
      ],
      "metadata": {
        "id": "2QvnQSrGoRS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "v30gvp49oVSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization *47mins"
      ],
      "metadata": {
        "id": "69AVK_jAqFk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the spaCy English model\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    # Join the tokens back into a sentence\n",
        "    text = ' '.join(tokens)\n",
        "    # Process the text using spaCy\n",
        "    doc = nlp(text)\n",
        "    # Lemmatize each token and return the lemmatized tokens\n",
        "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Apply lemmatization to the tokenized text column in the DataFrame\n",
        "df['text'] = df['text'].apply(lemmatize_tokens)"
      ],
      "metadata": {
        "id": "buRv7Inrplzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "bdmdjmOB1PX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Non-English Word\n",
        "but i ignore the word 'fuck' because it is frequent word in xsuicide class, remove it may lower down ability of detecting it."
      ],
      "metadata": {
        "id": "HzyPOIKd5KuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import words\n",
        "import nltk\n",
        "\n",
        "# Download the list of English words (if not already downloaded)\n",
        "nltk.download('words')\n",
        "\n",
        "# Load the set of English words\n",
        "english_words = set(words.words())\n",
        "\n",
        "# List of words to exclude from removal\n",
        "words_to_exclude = {'fuck'}  # Add your specific words here\n",
        "\n",
        "# Function to remove non-English words from a list of tokens\n",
        "def remove_non_english(tokens):\n",
        "    english_tokens = [\n",
        "        token if (token in english_words or token in words_to_exclude) else ''\n",
        "        for token in tokens]\n",
        "    return [token for token in english_tokens if token != '']\n",
        "\n",
        "# Apply the function to the 'text' column in the DataFrame\n",
        "df['text'] = df['text'].apply(remove_non_english)"
      ],
      "metadata": {
        "id": "wq-LPE5I3Hxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "-FVvG2am3O3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Cloud of Pre-processed data"
      ],
      "metadata": {
        "id": "B96MxPz95u1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suicide=df[df['class']=='suicide']['text']\n",
        "xsuicide=df[df['class']=='non-suicide']['text']\n",
        "\n",
        "def display_cloud(data):\n",
        "    plt.subplots(figsize=(10, 10))\n",
        "    wc = wordcloud.WordCloud(\n",
        "        background_color=\"black\",\n",
        "        colormap='viridis',\n",
        "        max_words=1000,\n",
        "        random_state=24\n",
        "    )\n",
        "\n",
        "    # Join all strings from the lists in 'data'\n",
        "    all_text = ' '.join([text for sublist in data for text in sublist])\n",
        "\n",
        "    plt.imshow(wc.generate(all_text))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display wordcloud of class 'suicide'\n",
        "display_cloud(suicide)"
      ],
      "metadata": {
        "id": "YCYa97wOztzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_cloud1(data):\n",
        "    plt.subplots(figsize=(10, 10))\n",
        "    wc = wordcloud.WordCloud(\n",
        "        background_color=\"white\",\n",
        "        max_words=1000,\n",
        "        random_state=24\n",
        "    )\n",
        "\n",
        "    # Join all strings from the lists in 'data'\n",
        "    all_text = ' '.join([text for sublist in data for text in sublist])\n",
        "\n",
        "    plt.imshow(wc.generate(all_text))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display wordcloud of class 'xsuicide'\n",
        "display_cloud1(xsuicide)"
      ],
      "metadata": {
        "id": "IZGzZ_gn0BnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the cleaned dataset"
      ],
      "metadata": {
        "id": "nlGBZwZR24cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_df = df.copy()"
      ],
      "metadata": {
        "id": "Olir3iX15jfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_df.head(10)"
      ],
      "metadata": {
        "id": "ghu4daxa5m54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partition"
      ],
      "metadata": {
        "id": "Ev-gdjW81PWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data ,test_data = train_test_split(preprocessed_df,test_size=0.2,random_state=10)\n",
        "\n",
        "print('Training data: ',len(train_data))\n",
        "print('Testing data: ',len(test_data))"
      ],
      "metadata": {
        "id": "N9fCFjPDW1hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting tokenized text from nltk to keras"
      ],
      "metadata": {
        "id": "zDQzHc5XN5io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Keras Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "#tokenizer.word_index['text']"
      ],
      "metadata": {
        "id": "S-84Ov_jN4o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_matrix(train_data['text'][0])"
      ],
      "metadata": {
        "id": "E1tZAYkKNUCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pad = tokenizer.texts_to_sequences(train_data['text'])\n",
        "test_pad = tokenizer.texts_to_sequences(test_data['text'])"
      ],
      "metadata": {
        "id": "7dJOMjcOrI69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(len(t) for t in preprocessed_df['text'])\n",
        "MAX_LENGTH"
      ],
      "metadata": {
        "id": "8-t98Cj1N1w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 200"
      ],
      "metadata": {
        "id": "HwzZY_NoiV2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)+1\n",
        "vocab_size"
      ],
      "metadata": {
        "id": "lzpqQrWRcTad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding"
      ],
      "metadata": {
        "id": "cqnIW7FTPlcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "train_data_padded = pad_sequences(train_pad, maxlen=MAX_LENGTH, padding='post')\n",
        "test_data_padded = pad_sequences(test_pad, maxlen=MAX_LENGTH, padding='post')"
      ],
      "metadata": {
        "id": "tXXYZvFePkcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_padded.shape"
      ],
      "metadata": {
        "id": "YbZFSC-QtFls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_padded"
      ],
      "metadata": {
        "id": "lEQ-WVkRGYyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Encoding"
      ],
      "metadata": {
        "id": "NT1lqPkXDQi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lbl_target=LabelEncoder()\n",
        "train_output=lbl_target.fit_transform(train_data['class'])\n",
        "test_output=lbl_target.fit_transform(test_data['class'])"
      ],
      "metadata": {
        "id": "kgYehM3iDBZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embedding"
      ],
      "metadata": {
        "id": "1TXhnDunM08N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read GloVe\n",
        "\n",
        "path_GloVe = '/content/drive/MyDrive/glove.6B.100d.txt'\n",
        "num_tokens = vocab_size\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "embedding_index = {}"
      ],
      "metadata": {
        "id": "l-k6NKwccBA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read word vectors\n",
        "with open(path_GloVe) as f:\n",
        "    for line in f:\n",
        "        word, coef = line.split(maxsplit=1)\n",
        "        coef = np.fromstring(coef, \"f\", sep=\" \")\n",
        "        embedding_index[word] = coef\n",
        "print(\"Found %s word vectors\" % len(embedding_index))\n",
        "\n",
        "# Assign word vectors to our dictionary/vocab\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print('Converted %d words (%d misses)' % (hits, misses))"
      ],
      "metadata": {
        "id": "Mwb6n-A_cp_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "ngIH6qSd1hgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Embedding,Dense,LSTM,Bidirectional,GlobalMaxPooling1D,Input,Dropout\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "CZIg0cTkHS2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "_bFKem6jWV0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback1 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/My Drive/SuicideDetect_LSTM',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "orCbwAYrHFtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM = Sequential()\n",
        "modelLSTM.add(Input(shape=(200,)))\n",
        "modelLSTM.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "modelLSTM.add(LSTM(16, return_sequences=True))\n",
        "modelLSTM.add(Dropout(0.2))\n",
        "modelLSTM.add(GlobalMaxPooling1D())\n",
        "\n",
        "modelLSTM.add(Dense(16,activation='relu'))\n",
        "modelLSTM.add(Dense(16,activation='relu'))\n",
        "\n",
        "modelLSTM.add(Dense(1,activation='sigmoid'))\n",
        "modelLSTM.compile(optimizer=tf.keras.optimizers.SGD(),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "modelLSTM.summary()"
      ],
      "metadata": {
        "id": "XRyK4Bvn1j_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historyLSTM=modelLSTM.fit(train_data_padded,\n",
        "                  train_output,\n",
        "                  validation_data=(test_data_padded,test_output),\n",
        "                  epochs=20,\n",
        "                  batch_size=32,\n",
        "                  callbacks=[callback1])"
      ],
      "metadata": {
        "id": "INLrSQfwHIS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.plot(historyLSTM.history['accuracy'], scalex=True, scaley=True, label='train acc')\n",
        "plt.plot(historyLSTM.history['val_accuracy'], scalex=True, scaley=True, label='val acc')\n",
        "fig.suptitle('LSTM Model Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "bYcQgqVnIYXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_pred = modelLSTM.predict(test_data_padded)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "\n",
        "f1 = f1_score(test_output, y_pred_binary)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "Qss5Y_a1OhaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "qmqBRafsvAyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback3 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/My Drive/GRUmodel-Suicide',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "3cmxkksQvAyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "modelGRU = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "modelGRU.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "# GRU layers\n",
        "modelGRU.add(GRU(units=64, input_shape=(200,), activation='relu', return_sequences=True))\n",
        "modelGRU.add(Dropout(0.25))\n",
        "\n",
        "modelGRU.add(GRU(units=32, activation='relu', return_sequences=True))\n",
        "modelGRU.add(Dropout(0.25))\n",
        "\n",
        "modelGRU.add(GRU(units=16, activation='relu'))\n",
        "modelGRU.add(Dropout(0.25))\n",
        "\n",
        "# Output layer\n",
        "modelGRU.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "modelGRU.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "modelGRU.summary()"
      ],
      "metadata": {
        "id": "KBOkev-jvAyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRUhistory=modelGRU.fit(train_data_padded,\n",
        "                  train_output,\n",
        "                  validation_data=(test_data_padded,test_output),\n",
        "                  epochs=10,\n",
        "                  batch_size=64,\n",
        "                  callbacks=[callback3])"
      ],
      "metadata": {
        "id": "RoeJyErpvAy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.plot(GRUhistory.history['accuracy'], scalex=True, scaley=True, label='train acc')\n",
        "plt.plot(GRUhistory.history['val_accuracy'], scalex=True, scaley=True, label='val acc')\n",
        "fig.suptitle('Model Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "QPWIUcXjvAy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_pred = modelGRU.predict(test_data_padded)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "\n",
        "f1 = f1_score(test_output, y_pred_binary)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "tVSpIJd90WqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "yCd3pOwTtiNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import MaxPooling1D,Flatten"
      ],
      "metadata": {
        "id": "2F_zsIgDbwnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "modelCNN = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "modelCNN.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=200, trainable=False))\n",
        "\n",
        "# Convolutional layers\n",
        "modelCNN.add(Conv1D(16, 5, padding = 'same', activation='relu'))\n",
        "modelCNN.add(MaxPooling1D(5))\n",
        "modelCNN.add(Conv1D(16 , 5 , padding = 'same', activation = 'relu'))\n",
        "modelCNN.add(MaxPooling1D(5))\n",
        "modelCNN.add(Conv1D(16 , 5 , padding = 'same', activation = 'relu'))\n",
        "modelCNN.add(MaxPooling1D(5))\n",
        "\n",
        "modelCNN.add(Flatten())\n",
        "# Dense layers\n",
        "modelCNN.add(Dense(128, activation='relu'))\n",
        "modelCNN.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "modelCNN.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "modelCNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "modelCNN.summary()"
      ],
      "metadata": {
        "id": "jqV2H1MoKaHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback4 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/My Drive/CNN-Suicide',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "gTuezr3KKaHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historyCNN=modelCNN.fit(train_data_padded,\n",
        "                  train_output,\n",
        "                  validation_data=(test_data_padded,test_output),\n",
        "                  epochs=20,\n",
        "                  batch_size=32,\n",
        "                  callbacks=[callback4])"
      ],
      "metadata": {
        "id": "uFOt8Lw5KaHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.plot(historyCNN.history['accuracy'], scalex=True, scaley=True, label='train acc')\n",
        "plt.plot(historyCNN.history['val_accuracy'], scalex=True, scaley=True, label='val acc')\n",
        "fig.suptitle('Model Accuracy(CNN)', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "buL7RMcC-47-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_pred = modelCNN.predict(test_data_padded)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "\n",
        "f1 = f1_score(test_output, y_pred_binary)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "lvm93pE9-NPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "ibxgcTS0KpTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "qqISWTH2SOvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner"
      ],
      "metadata": {
        "id": "yHV3Cz1FF0PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "-rLJhYKFK0By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_LSTM_model(hp):\n",
        "\n",
        "    modelLSTM = Sequential()\n",
        "    modelLSTM.add(Input(shape=(200,)))\n",
        "    modelLSTM.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "    modelLSTM.add(LSTM(hp.Choice('LSTM_units', values=[16, 32, 64]), return_sequences=True))\n",
        "    modelLSTM.add(Dropout(hp.Choice('dropout', values=[0.2,0.5])))\n",
        "    modelLSTM.add(GlobalMaxPooling1D())\n",
        "\n",
        "    modelLSTM.add(Dense(hp.Choice('units1', values=[16, 64, 128]),activation='relu'))\n",
        "    modelLSTM.add(Dense(hp.Choice('units2', values=[16, 64, 128]),activation='relu'))\n",
        "\n",
        "    modelLSTM.add(Dense(1,activation='sigmoid'))\n",
        "    modelLSTM.compile(optimizer=hp.Choice('optimizer', values=['SGD','adam']),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    return modelLSTM"
      ],
      "metadata": {
        "id": "tt2JB3vzF-67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_tuner = keras_tuner.RandomSearch(\n",
        "    build_LSTM_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2)"
      ],
      "metadata": {
        "id": "GVgHWB3jJXBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "WHQkgRNiJYfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_tuner.search(train_data_padded, train_output, epochs=5, validation_data=(test_data_padded,test_output))"
      ],
      "metadata": {
        "id": "9X8Sl7vZJYlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters and their corresponding model performance\n",
        "best_trial = LSTM_tuner.oracle.get_best_trials()[0]\n",
        "best_hyperparameters = best_trial.hyperparameters\n",
        "best_model_performance = best_trial.metrics.get_best_value('val_accuracy')\n",
        "\n",
        "# Display the results\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hyperparameters.values)\n",
        "print(\"Best Model Performance (Validation Accuracy):\")\n",
        "print(best_model_performance)"
      ],
      "metadata": {
        "id": "QTPXAadSJi6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuned LSTM"
      ],
      "metadata": {
        "id": "sdw1FB-cmKjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback8 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/My Drive/Tuned-LSTM-Suicide',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "Iw5q0HSdyvhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model architecture with the best hyperparameters\n",
        "best_LSTM_model = build_LSTM_model(best_hyperparameters)\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "history_LSTM_Tuned = best_LSTM_model.fit(train_data_padded, train_output,\n",
        "               shuffle=True,\n",
        "               validation_data=(test_data_padded,test_output),\n",
        "               callbacks=[callback8],\n",
        "               epochs=20,\n",
        "               verbose=1)"
      ],
      "metadata": {
        "id": "DcHHjaXoO69s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.plot(history_LSTM_Tuned.history['accuracy'], scalex=True, scaley=True, label='train acc')\n",
        "plt.plot(history_LSTM_Tuned.history['val_accuracy'], scalex=True, scaley=True, label='val acc')\n",
        "fig.suptitle('Tuned LSTM Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "c9nVwof9y8Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_pred = best_LSTM_model.predict(test_data_padded)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "\n",
        "f1 = f1_score(test_output, y_pred_binary)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "NK_yVQtnzCya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "qKk1qgN3R-sH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subsampling"
      ],
      "metadata": {
        "id": "74m0kmFJIkeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert from nparray to Dataframe\n",
        "train_data_padded_df = pd.DataFrame(train_data_padded)\n",
        "train_output_df = pd.DataFrame(train_output)\n",
        "\n",
        "test_data_padded_df = pd.DataFrame(test_data_padded)\n",
        "test_output_df = pd.DataFrame(test_output)\n",
        "\n",
        "#Subsampling the training set to 100,000 instances\n",
        "subsampled_train = pd.concat([train_data_padded_df, train_output_df], axis=1).sample(n=100000, random_state=42)\n",
        "\n",
        "#The testing set remains unchanged with 40,000 instances\n",
        "subsampled_test = pd.concat([test_data_padded_df, test_output_df], axis=1)"
      ],
      "metadata": {
        "id": "1l0ETyfvG9s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subsampled_train.shape)\n",
        "print(subsampled_test.shape)"
      ],
      "metadata": {
        "id": "mHc7gx0zHMlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsampled_X_train = subsampled_train.iloc[:, :-1]\n",
        "subsampled_Y_train = subsampled_train.iloc[:,-1]\n",
        "subsampled_X_test = subsampled_test.iloc[:, :-1]\n",
        "subsampled_Y_test = subsampled_test.iloc[:,-1]\n",
        "\n",
        "print(subsampled_X_train.shape)\n",
        "print(subsampled_Y_train.shape)\n",
        "print(subsampled_X_test.shape)\n",
        "print(subsampled_Y_test.shape)"
      ],
      "metadata": {
        "id": "DxxzbB6oHNCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsampled_Y_train.value_counts()"
      ],
      "metadata": {
        "id": "Y7XF0AyPJc6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsampled_Y_test.value_counts()"
      ],
      "metadata": {
        "id": "TYPnKxEEIxbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_GRU_model(hp):\n",
        "\n",
        "    modelGRU = Sequential()\n",
        "\n",
        "    modelGRU.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "    modelGRU.add(GRU(units=hp.Choice('units1', values=[64, 128]), input_shape=(200,), activation='relu', return_sequences=True))\n",
        "    modelGRU.add(Dropout(0.25))\n",
        "\n",
        "    modelGRU.add(GRU(units=hp.Choice('units2', values=[32, 64]), activation='relu', return_sequences=True))\n",
        "    modelGRU.add(Dropout(0.25))\n",
        "\n",
        "    modelGRU.add(GRU(units=hp.Choice('units3', values=[16, 32]), activation='relu'))\n",
        "    modelGRU.add(Dropout(0.25))\n",
        "\n",
        "    modelGRU.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    modelGRU.compile(optimizer=hp.Choice('optimizer', values=['SGD','adam']),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    return modelGRU"
      ],
      "metadata": {
        "id": "II0UbQFbR-sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRUmodel_tuner = keras_tuner.RandomSearch(\n",
        "    build_GRU_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1)"
      ],
      "metadata": {
        "id": "L2h7biUeR-sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRUmodel_tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "nriNEKUaR-sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRUmodel_tuner.search(subsampled_X_train, subsampled_Y_train, epochs=2, validation_data=(subsampled_X_test,subsampled_Y_test))"
      ],
      "metadata": {
        "id": "sOFPIJsxAR3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters and their corresponding model performance\n",
        "best_trial = GRUmodel_tuner.oracle.get_best_trials()[0]\n",
        "best_hyperparameters = best_trial.hyperparameters\n",
        "best_model_performance = best_trial.metrics.get_best_value('val_accuracy')\n",
        "\n",
        "# Display the results\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hyperparameters.values)\n",
        "print(\"Best Model Performance (Validation Accuracy):\")\n",
        "print(best_model_performance)"
      ],
      "metadata": {
        "id": "sxUyOqB9AR3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuned GRU"
      ],
      "metadata": {
        "id": "dBa1jJNDp219"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbackGRU = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/My Drive/TunedGRU-Suicide',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "9mv0InLTx5AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model architecture with the best hyperparameters\n",
        "best_GRU_model = build_GRU_model(best_hyperparameters)\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "history_TunedGRU = best_GRU_model.fit(train_data_padded, train_output,\n",
        "               shuffle=True,\n",
        "               validation_data=(test_data_padded,test_output),\n",
        "               callbacks=[callbackGRU],\n",
        "               epochs=10,\n",
        "               batch_size=64,\n",
        "               verbose=1)"
      ],
      "metadata": {
        "id": "YHsx5CHeAR3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.plot(history_TunedGRU.history['accuracy'], scalex=True, scaley=True, label='train acc')\n",
        "plt.plot(history_TunedGRU.history['val_accuracy'], scalex=True, scaley=True, label='val acc')\n",
        "fig.suptitle('Tuned Model Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "09BxJnDY-NlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_pred = best_GRU_model.predict(test_data_padded)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "\n",
        "f1 = f1_score(test_output, y_pred_binary)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "KduzFsHFAR3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "0sx1axKjK5vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_CNN_model(hp):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Embedding layer\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=200, trainable=False))\n",
        "\n",
        "    kernel_size = hp.Choice('kernelsize', values=[3, 5, 7])\n",
        "    conv_filter = hp.Choice('units1', values=[64, 128])\n",
        "\n",
        "    # Convolutional layers\n",
        "    model.add(Conv1D(conv_filter, kernel_size, padding = 'same', activation='relu'))\n",
        "    model.add(MaxPooling1D(5))\n",
        "    model.add(Conv1D(conv_filter, kernel_size , padding = 'same', activation = 'relu'))\n",
        "    model.add(MaxPooling1D(5))\n",
        "    model.add(Conv1D(conv_filter, kernel_size , padding = 'same', activation = 'relu'))\n",
        "    model.add(MaxPooling1D(5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    # Dense layers\n",
        "    model.add(Dense(hp.Choice('units2', values=[16, 64]), activation='relu'))\n",
        "    model.add(Dense(hp.Choice('units3', values=[16, 64]), activation='relu'))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=hp.Choice('optimizer', values=['SGD','adam']), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mOfZFJIrptKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "\n",
        "CNN_tuner = keras_tuner.RandomSearch(\n",
        "    build_CNN_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2)"
      ],
      "metadata": {
        "id": "le6MJMr_ptKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "QkO8JXI9ptKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_tuner.search(train_data_padded, train_output, epochs=5, validation_data=(test_data_padded,test_output))"
      ],
      "metadata": {
        "id": "JGCLFBzcptKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters and their corresponding model performance\n",
        "best_trial = CNN_tuner.oracle.get_best_trials()[0]\n",
        "best_hyperparameters = best_trial.hyperparameters\n",
        "best_model_performance = best_trial.metrics.get_best_value('val_accuracy')\n",
        "\n",
        "# Display the results\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_hyperparameters.values)\n",
        "print(\"Best Model Performance (Validation Accuracy):\")\n",
        "print(best_model_performance)"
      ],
      "metadata": {
        "id": "jGdJ1u8uptKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuned CNN"
      ],
      "metadata": {
        "id": "qWFPI6zTqCIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback5 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/My Drive/TunedCNN-Suicide',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "tQDWIh-1WTfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model architecture with the best hyperparameters\n",
        "best_CNN_model = build_CNN_model(best_hyperparameters)\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "history_TunedCNN = best_CNN_model.fit(train_data_padded, train_output,\n",
        "                                      shuffle=True,\n",
        "                                      validation_data=(test_data_padded,test_output),\n",
        "                                      callbacks=[callback5],\n",
        "                                      epochs=20,\n",
        "                                      verbose=1)"
      ],
      "metadata": {
        "id": "PU3nlgfEptKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "plt.plot(history_TunedCNN.history['accuracy'], scalex=True, scaley=True, label='train acc')\n",
        "plt.plot(history_TunedCNN.history['val_accuracy'], scalex=True, scaley=True, label='val acc')\n",
        "fig.suptitle('Model Accuracy(Tuned CNN)', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "LwKcnPKbptKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_pred_TunedCNN = best_CNN_model.predict(test_data_padded)\n",
        "y_pred_binary = (y_pred_TunedCNN > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "\n",
        "f1 = f1_score(test_output, y_pred_binary)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "IAby7PZhVOoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models \tAccuracy\tF1 Score\n",
        "LSTM\t    91.83%\t91.57%\n",
        "Tuned LSTM\t93.07%\t92.27%\n",
        "\n",
        "GRU \t    93.19%\t93.01%\n",
        "*Tuned GRU\t93.36%\t92.74%*\n",
        "\n",
        "CNN \t    91.70%\t91.38%\n",
        "Tuned CNN\t92.18%\t91.09%\n"
      ],
      "metadata": {
        "id": "UE1xvaVSlrQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM model improved by 1.24% and its F1-score also has slightly improved. Important to note that, the team discovered that the F1-scores have slightly decreased for GRU and CNN models after tuned. According to the results, tuned GRU model was chosen for our suicide and depression detection classification model because it has the best performance with the highest accuracy of 93.36% and 92.7% F1-score"
      ],
      "metadata": {
        "id": "FLibceTAlrQE"
      }
    }
  ]
}